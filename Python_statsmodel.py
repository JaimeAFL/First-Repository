# -----------------------------------------
### MODELSO ESTADISTICOS: STATS-MODELS ###
# -----------------------------------------


# -------------------------------------------------------------------------------------------------------
# --( 1 )-- MODELOS ESTAD√çSTICOS: STATSMODELS --
# -------------------------------------------------------------------------------------------------------

## MODELOS LINEALES SIMPLES Y M√öLTIPLES ##
# -------------------------------------------------------------------------
# Statsmodels es una librer√≠a para Python especializada en la exploraci√≥n, estimaci√≥n y evaluaci√≥n de modelos, 
# ajuste de par√°metros y realizaci√≥n de tests estad√≠sticos sobre conjuntos de datos y distribuciones.
# Statsmodels est√° construido sobre la base de NumPy, y se integra con las estructuras de datos de Pandas. 
# Adem√°s, incluye la posibilidad de definir modelos siguiendo la sintaxis de f√≥rmulas de R, 
# lo que facilita la transici√≥n para los usuarios de este lenguaje.

# Cargamos las librer√≠as NumPy y Pandas
import numpy as np
import pandas as pd
from pandas import Series, DataFrame
from pathlib import Path
# Cargamos Matplotlib y Seaborn
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
# Cargamos los datos de gasto en publicidad

ads = pd.read_csv("/workspaces/First-Repository/U09_datasets/advertising.csv", sep = ";")

# La regresi√≥n lineal es dibujar la ‚Äúmejor l√≠nea‚Äù que pasa por un mont√≥n de puntos para predecir algo.
# - Tienes una variable que quieres predecir: ùëå (por ejemplo, notas).
# - Tienes una variable que crees que explica Y: ùëã (por ejemplo, horas de estudio).

# Buscas una l√≠nea: Y = b0 + b1X
# - b0 es la intersecci√≥n con el eje Y (cuando X = 0). por d√≥nde corta la l√≠nea el eje vertical.
# - b1 es la pendiente de la l√≠nea (el cambio en Y por cada unidad de cambio en X). 
#   cu√°nto sube o baja Y si aumentas X en 1.

# C√≥mo se elige la ‚Äúmejor l√≠nea‚Äù
# - Calcula los errores (residuos): diferencia entre lo observado y lo que dice la l√≠nea.
# - El m√©todo de m√≠nimos cuadrados elige la l√≠nea que hace peque√±a la suma de errores al cuadrado.

# Qu√© te dice el resultado
# Pendiente b1: : efecto por unidad de X. Positiva sube, negativa baja.
# Intersecci√≥n b0: valor de Y cuando X = 0. (a veces no tiene sentido pr√°ctico, no pasa nada).
# R**2: de 0 a 1. Qu√© porcentaje de la variaci√≥n de Y explica la l√≠nea.
# Valores p: si son bajos (< 0.05), hay evidencia de relaci√≥n.

# Cu√°ndo funciona bien
# Relaci√≥n m√°s o menos recta entre X y Y.
# Errores sin patr√≥n raro y de tama√±o parecido.
# Sin puntos extremos que lo destrocen.

# Ahora revisamos gr√°ficamente la estructura de los datos.
# Nos preparamos los datos de forma que sea m√°s f√°cil pintarlos
ads_m = ads.melt(id_vars='Sales', value_vars=['TV','Radio','Newspaper'], var_name='Media', value_name='Spend')

# Representamos en una rejilla las ventas seg√∫n gasto en cada medio
g = sns.FacetGrid(ads_m, col='Media', col_order=['TV','Radio','Newspaper'],
                  sharex=False, height=2.2, aspect=1.4)
g.map(sns.regplot, 'Spend', 'Sales', fit_reg=False, scatter_kws={'s':20})
g.set_axis_labels('Spend', 'Sales')
g.set_titles('Media = {col_name}')
BASE = Path.cwd()
out = BASE / "graficos_seaborn" / "grafico_ventas_model.png"
out.parent.mkdir(parents=True, exist_ok=True)
g.figure.savefig(out, dpi=150, bbox_inches="tight")
print (f"OK -> {out.resolve()}")
plt.close(plt.gcf())
